<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html>
<head><meta http-equiv="Content-Type" content="text/html; charset=utf-8">
	<meta name="viewport" content="width=800">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="generator" content="HTML Tidy for Linux/x86 (vers 11 February 2007), see www.w3.org">
    <style type="text/css">
    /* Color scheme stolen from Sergey Karayev */
    a {
    color: #1772d0;
    text-decoration:none;
    }
    a:focus, a:hover {
    color: #f09228;
    text-decoration:none;
    }
    body,td,th,tr,p,a {
    font-family: 'Lato', Verdana, Helvetica, sans-serif;
    font-size: 14px
    }
    .hp-photo{ width:240px; height:240px; border-radius:240px; -webkit-border-radius:240px; -moz-border-radius:240px; }
    strong {
    font-family: 'Lato', Verdana, Helvetica, sans-serif;
    font-size: 14px;
    }
    heading {
    font-family: 'Lato', Verdana, Helvetica, sans-serif;
    font-size: 24px;
    }
    papertitle {
    font-family: 'Lato', Verdana, Helvetica, sans-serif;
    font-size: 15px;
    font-weight: 700
    }
    name {
    font-family: 'Lato', Verdana, Helvetica, sans-serif;
    font-size: 32px;
    }
    .one
    {
    width: 160px;
    height: 160px;
    position: relative;
    }
    .two
    {
    width: 160px;
    height: 160px;
    position: absolute;
    transition: opacity .2s ease-in-out;
    -moz-transition: opacity .2s ease-in-out;
    -webkit-transition: opacity .2s ease-in-out;
    }
    .fade {
     transition: opacity .2s ease-in-out;
     -moz-transition: opacity .2s ease-in-out;
     -webkit-transition: opacity .2s ease-in-out;
    }
    span.highlight {
        background-color: #ffffd0;
    }
    </style>

    <title>Aishan Liu | Beihang University</title>
    <!--<link rel="stylesheet" type="text/css" href="/imgs/css" >-->
    <link rel="icon" type="image/jpg" href="./imgs/buaa_icon.jpg">
</head>

<body>
<table width="800" border="0" align="center" cellspacing="0" cellpadding="0">
<tbody>
<tr>
<td>


    <!--SECTION 1 -->
    <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
            <tbody><tr>

              <td width="68%" valign="middle">
                <p align="left"><name>Aishan Liu (刘艾杉)</name></p>
				
				<p align="left"><font size="4" face="verdana">Assistant Professor</font></p>
				<p align="left"><a href="http://www.nlsde.buaa.edu.cn/">State Key Laboratory of Software Development Environment</a></p>
				
				<p align="left"> <a href="https://scse.buaa.edu.cn/">SCSE</a>, <a href="https://www.buaa.edu.cn/">Beihang University</a>, Beijing, China</>

                  <p align="justify">

				  He received the Ph.D. degree in 2021 from <a href="https://www.buaa.edu.cn/">Beihang University</a>, supervised by Prof. <a href="http://sites.nlsde.buaa.edu.cn/~liwei/">Wei Li</a> 
                    and Prof. <a href="https://xlliu-beihang.github.io/">Xianglong Liu</a>.
                    Before that, He obtained the M.Sc and B.Sc degree from <a href="https://www.buaa.edu.cn/">Beihang University</a> at 2016 and 2013, respectively, 
					where he was supervised by Prof. <a href="http://sites.nlsde.buaa.edu.cn/~liwei/">Wei Li</a>. 
					
					</br></br>
					In his Ph.D study, during 2021, he was a visiting student at <a href="https://www.berkeley.edu/">UC Berkeley</a>, supervised by Prof. <a href="http://people.eecs.berkeley.edu/~dawnsong/">Dawn Song</a>.
					During 2020, he was a visiting student at <a href="https://www.sydney.edu.au/">the University of Sydney</a>, supervised by Prof. <a href="https://www.sydney.edu.au/engineering/about/our-people/academic-staff/dacheng-tao.html">Dacheng Tao</a>. 
					In 2019, he interned at <a href="https://ai.tencent.com/ailab/zh/index">AI Lab</a> at <a href="https://www.tencent.com/">Tencent</a> supported by <a href="https://ur.tencent.com/talent/program">Tecent Rhino-Bird Elite Program</a>, supervised by Prof. <a href="https://lwwangcse.github.io/">Liwei Wang</a>. He serves as a reviewer for the top conferences and journals such as 
					CVPR, ICML, ICCV, ECCV, NeurIPS, ICLR, AAAI, TPAMI, IJCV, TIP, etc.

					<br><br><strong>Email:</strong> liuaishan AT buaa DOT edu DOT cn
	            </br>
                </p><p align="center">
                    <a href="https://scholar.google.com/citations?user=88tzr_sAAAAJ&hl=zh-CN&oi=ao">Google Scholar</a> &nbsp;/&nbsp;
                    <a href="https://github.com/liuaishan"> Github </a> &nbsp;/&nbsp;
					<a href="https://dblp.org/pid/177/5658.html"> dblp </a>
                </p>
              </td>
			  <td align="right"> <img class="hp-photo" src="./imgs/aishan.jpg" style="width: 310;height:320"></td></tr>

            
            </tbody>
          </table>

    <!--SECTION 2 -->
    <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
       <tbody><tr>
          <td>
          <heading>Research</heading>
		  <p align="justify">My research interests include some sub-fields of <b>Computer Vision</b> and <b>Deep Learning</b>:</p>
<ul>
<li><p><b>Robust Deep Learning</b>: Adversarial Example, Backdoor Attacks, Model Robustness</p>
</li>
<li><p><b>AI Testing</b>: AI Safety Evaluation and Test</p>
</li>
</ul>
</p></br>

<strong><font color="red">Prospective students</font></strong>: Our group has positions for PhD students, Master students, and visiting students. If you are interested, please send me an email with your CV and publications (if any).
     
       </tbody>
    </table>

    <!--SECTION 3 -->
    <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
       <tbody><tr>
          <td><heading>News</heading>
		  
		  <p style="font-size:13px"> <strong><font color="red">[Call for Papers]</font></strong> I am serving as the Guest Editor on <a href="https://www.journals.elsevier.com/pattern-recognition/call-for-papers/practical-deep-learning-in-the-wild">Practical Deep Learning in the Wild</a> at Pattern Recognition (JCR Q1). Please submit your papers!</p>
	      <p style="font-size:13px"> <strong><font color="red">[Workshop@CVPR2023]</font></strong> I am co-organizing the <a href="https://robustart.github.io/">3rd Workshop of Adversarial Machine Learning on Computer Vision: Art of Robustness</a> on CVPR 2023. Please submit your papers and participate the challenge to win prizes!</p>
			
		  <p style="font-size:13px"> <strong><font color="red">[Workshop@AAAI2023]</font></strong> I am co-organizing the <a href="https://practical-dl.github.io/">2nd International Workshop on Practical Deep Learning in the Wild</a> on AAAI 2023. Please submit your papers and participate the challenge to win $17K prizes!</p>
			
			<p style="font-size:13px"> <strong>[<font color="red">2023.02</font>]</strong>  One paper accepted by USENIX Security Symposium 2023.</p>
			
			<p style="font-size:13px"> <strong>[<font color="red">2023.02</font>]</strong>  One paper accepted by Sixth Conference on Machine Learning and Systems (MLSys 2023).</p>
			
			<p style="font-size:13px"> <strong>[<font color="red">2023.01</font>]</strong>  Two papers accepted by Pattern Recognition and 智能安全.</p>
			
			<p style="font-size:13px"> <strong>[2022.12]</strong>  Two papers accepted by IEEE TMM and 计算机学报 (Chinese Journal of Computers, CCF-A).</p>
			
			<p style="font-size:13px"> <strong>[2022.11]</strong>  One paper accepted by AAAI 2023.</p>
			
			<p style="font-size:13px"> <strong>[2022.08]</strong>  One paper accepted by ACM CCS 2022.</p>
			
			<p style="font-size:13px"> <strong>[2022.07]</strong>  One paper accepted by IEEE CYB.</p>
			
			<p style="font-size:13px"> <strong>[2022.06]</strong>  Three papers accepted by ACM Multimedia 2022.</p>
		
			<p style="font-size:13px"> <strong>[2022.03]</strong>  Two papers accepted by CVPR 2022.</p>
						
			<p style="font-size:13px"> <strong>[2022.01]</strong> One paper accepted by ICLR 2022.</p>
			
			<p style="font-size:13px"> <strong>[2021.10]</strong> Two papers accepted by IEEE TIP.</p>
			
			<p style="font-size:13px"> <strong>[2021.09]</strong> We released the first comprehensive Robustness investigation benchmark (<a href="http://robust.art/">RobustART</a>) on large-scale dataset ImageNet regarding ARchitectural design (1000+) and Training techniques (10+).</p>
			
			<p style="font-size:13px"> <strong>[2021.08]</strong> One paper accepted by IEEE TNNLS.</p>
			
			<p style="font-size:13px"> <strong>[2021.08]</strong> One paper accepted by ACM Multimedia 2021.</p>
			
			



          </td>
       </tr></tbody>
    </table>

    <!--SECTION 4 -->
    <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
        <tbody><tr>
          <td><heading>Publications</heading>
          </td>
          </tr>
		  </tbody>
    </table>

	<h3>&nbsp;&nbsp;&nbsp;&nbsp;Conference Papers</h3>
    <!--SECTION 5 -->
    <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
		<tbody>
				
		<tr>
		
		<td width="20%"><img src="./imgs/MLSys23.png" alt="MLSys 2023" width="180" height = "160" style="border-style: none"></td>
            <td width="80%" valign="top">
                 <p><a href="#">
                 <papertitle>SysNoise: Exploring and Benchmarking Training-Deployment System Inconsistency</papertitle></a>
                 <br>Yan Wang*, Yuhang Li*, Ruihao Gong*, <strong>Aishan Liu*</strong>, Yanfei Wang, Jian Hu, Yongqiang Yao, Yunchen Zhang, Tianzi Xiao, Fengwei Yu, Xianglong Liu.<br>(* indicates equal contributions)<br>
                 <em>Conference on Machine Learning and Systems</em>, 2023
				 <br>
                 <a href="#">pdf</a>  /
				<a href="https://github.com/silvercherry/Improving-Robust-Fairness-via-Balance-Adversarial-Training"><font color="red">Project page</font></a>
                 <iframe src="https://ghbtns.com/github-btn.html?user=silvercherry&repo=Improving-Robust-Fairness-via-Balance-Adversarial-Training&type=star&count=true&size=small" frameborder="0" scrolling="0" width="120px" height="20px"></iframe>
				
               
                 <p align="justify" style="font-size:13px">This paper for the first time introduces SysNoise, a frequently occurred but often overlooked noise in the deep learning training-deployment cycle. In particular, SysNoise happens when the source training system switches to a disparate target system in deployments, where various tiny system mismatch adds up to a non-negligible difference.</p>
                <p></p>
            </td>
        </tr>
		
		<tr>
		
		<td width="20%"><img src="./imgs/USENIX-2023.png" alt="USENIX Sec 2023" width="180" height = "160" style="border-style: none"></td>
            <td width="80%" valign="top">
                 <p><a href="https://arxiv.org/abs/2302.09491">
                 <papertitle>X-Adv: Physical Adversarial Object Attacks against X-ray Prohibited Item Detection</papertitle></a>
                 <br><strong>Aishan Liu*</strong>, Jun Guo*, Jiakai Wang, Siyuan Liang, Renshuai Tao, Wenbo Zhou, Cong Liu, Xianglong Liu, Dacheng Tao.<br>(* indicates equal contributions)<br>
                 <em>USENIX Security Symposium</em>, 2023
				 <br>
                 <a href="https://arxiv.org/abs/2302.09491">pdf</a>  /
				<a href="https://github.com/DIG-Beihang/X-adv"><font color="red">Project page</font></a>
                 <iframe src="https://ghbtns.com/github-btn.html?user=DIG-Beihang&repo=X-adv&type=star&count=true&size=small" frameborder="0" scrolling="0" width="120px" height="20px"></iframe>
				
               
                 <p align="justify" style="font-size:13px">  This paper takes the first step toward the study of physical adversarial attacks targeted at X-ray prohibited item detection, and reveals the serious threats posed by such attacks in this safety-critical scenario.</p>
                <p></p>
            </td>
        </tr>
		
		
		<tr>
		
		<td width="20%"><img src="./imgs/AAAI-2023.png" alt="AAAI 2023" width="180" height = "160" style="border-style: none"></td>
            <td width="80%" valign="top">
                 <p><a href="https://arxiv.org/abs/2209.07534">
                 <papertitle>Improving Robust Fairness via Balance Adversarial Training</papertitle></a>
                 <br>Chunyu Sun, Chenye Xu, Chengyuan Yao, Siyuan Liang, Yichao Wu, Ding Liang, XiangLong Liu, <strong>Aishan Liu<sup>&spades;</sup></strong>.<br>(&spades; indicates corresponding author)<br>
                 <em>AAAI Conference on Artificial Intelligence (AAAI)</em>, 2023
				 <br>
                 <a href="https://arxiv.org/abs/2209.07534">pdf</a>  /
				<a href="https://github.com/silvercherry/Improving-Robust-Fairness-via-Balance-Adversarial-Training"><font color="red">Project page</font></a>
                 <iframe src="https://ghbtns.com/github-btn.html?user=silvercherry&repo=Improving-Robust-Fairness-via-Balance-Adversarial-Training&type=star&count=true&size=small" frameborder="0" scrolling="0" width="120px" height="20px"></iframe>
				
               
                 <p align="justify" style="font-size:13px"> This paper proposes Balance Adversarial Training (BAT) to address the robust fairness problem of adversarial training, which is known as the severe disparity of accuracy and robustness between different classes for the adversarially-trained models.</p>
                <p></p>
            </td>
        </tr>
		
		<tr>
		
		<td width="20%"><img src="./imgs/ACMCCS-1.png" alt="ACM CCS 2022" width="180" height = "160" style="border-style: none"></td>
            <td width="80%" valign="top">
                 <p><a href="#">
                 <papertitle>Harnessing Perceptual Adversarial Patches for Crowd Counting</papertitle></a>
                 <br>Shunchang Liu, Jiakai Wang, <strong>Aishan Liu<sup>&spades;</sup></strong>, Yingwei Li, Yijie Gao, Xianglong Liu, Dacheng Tao.<br>(&spades; indicates corresponding author)<br>
                 <em> ACM Conference on Computer and Communications Security (ACM CCS)</em>, 2022
				 <br>
                 <a href="https://arxiv.org/pdf/2109.07986v1.pdf">pdf</a>  /
				<a href="https://github.com/shunchang-liu/PAP-Pytorch"><font color="red">Project page</font></a>
                 <iframe src="https://ghbtns.com/github-btn.html?user=shunchang-liu&repo=PAP-Pytorch&type=star&count=true&size=small" frameborder="0" scrolling="0" width="120px" height="20px"></iframe>
				
               
                 <p align="justify" style="font-size:13px"> This paper proposes the Perceptual Adversarial Patch (PAP) generation to attack crowd counting models; in addition, we surprisingly found that our adversarial patches could also be utilized to benefit the performance of vanilla models for alleviating several challenges including cross datasets and complex backgrounds. </p>
                <p></p>
            </td>
        </tr>

		
		<tr>
		
		<td width="20%"><img src="./imgs/ACMMM2022-1.png" alt="ACMMM 2022" width="180" height = "160" style="border-style: none"></td>
            <td width="80%" valign="top">
                 <p><a href="https://dl.acm.org/doi/10.1145/3503161.3547989">
                 <papertitle>Generating Transferable Adversarial Examples against Vision Transformers</papertitle></a>
                 <br>Yuxuan Wang, Jiakai Wang, Zixin Yin, Ruihao Gong, Jingyi Wang, <strong>Aishan Liu</strong>, Xianglong Liu.<br>
                 <em>ACM Multimedia (ACM MM)</em>, 2022
				 <br>
                 <a href="https://dl.acm.org/doi/10.1145/3503161.3547989">pdf</a>  /
				<a href="https://github.com/nlsde-safety-team/ATA"><font color="red">Project page</font></a>
                 <iframe src="https://ghbtns.com/github-btn.html?user=nlsde-safety-team&repo=ATA&type=star&count=true&size=small" frameborder="0" scrolling="0" width="120px" height="20px"></iframe>
				
               
                 <p align="justify" style="font-size:13px"> We propose an Architecture-oriented Transferable Attacking (ATA) framework to generate transferable adversarial examples for ViTs by activating the uncertain attention and perturbing the sensitive embedding.</p>
                <p></p>
            </td>
        </tr>
		
		<tr>
		
		<td width="20%"><img src="./imgs/ACMMM2022-2.png" alt="ACMMM 2022" width="180" height = "160" style="border-style: none"></td>
            <td width="80%" valign="top">
                 <p><a href="https://dl.acm.org/doi/abs/10.1145/3503161.3548416">
                 <papertitle>Imitated Detectors: Stealing Knowledge of Black-box Object Detectors</papertitle></a>
                 <br>Siyuan Liang, <strong>Aishan Liu</strong>, Jiawei Liang, Longkang Li, Yang Bai, Xiaochun Cao.<br>
                 <em>ACM Multimedia (ACM MM)</em>, 2022
				 <br>
                 <a href="https://dl.acm.org/doi/abs/10.1145/3503161.3548416">pdf</a>  /
				<a href="https://github.com/LiangSiyuan21/Imitated-Detectors"><font color="red">Project page</font></a>
                 <iframe src="https://ghbtns.com/github-btn.html?user=LiangSiyuan21&repo=Imitated-Detectors&type=star&count=true&size=small" frameborder="0" scrolling="0" width="120px" height="20px"></iframe>
				
               
                 <p align="justify" style="font-size:13px"> We for the first time reveal that black-box victim object detectors can be easily replicated without knowing the model structure and training data.</p>
                <p></p>
            </td>
        </tr>
		
				<tr>
		
		<td width="20%"><img src="./imgs/ACMMM2022-3.png" alt="ACMMM 2022" width="180" height = "160" style="border-style: none"></td>
            <td width="80%" valign="top">
                 <p><a href="https://dl.acm.org/doi/abs/10.1145/3503161.3548075">
                 <papertitle>Few-shot X-ray Prohibited Item Detection: A Benchmark and Weak-feature Enhancement Network</papertitle></a>
                 <br>Renshuai Tao, tianbo Wang, Ziyang Wu, Cong Liu, <strong>Aishan Liu</strong>, Xianglong Liu.<br>
                 <em>ACM Multimedia (ACM MM)</em>, 2022
				 <br>
                 <a href="https://dl.acm.org/doi/abs/10.1145/3503161.3548075">pdf</a>  /
				<a href="#"><font color="red">Project page</font></a>
                 <iframe src="https://ghbtns.com/github-btn.html?user=nlsde-safety-team&repo=DefensivePatch&type=star&count=true&size=small" frameborder="0" scrolling="0" width="120px" height="20px"></iframe>
				
               
                 <p align="justify" style="font-size:13px"> We propose the first X-ray few-shot object detection dataset on the typical industrial X-ray security inspection scenario.</p>
                <p></p>
            </td>
        </tr>
		
		
		<tr>
		
		<td width="20%"><img src="./imgs/CVPR2022-1.png" alt="CVPR 2022" width="180" height = "160" style="border-style: none"></td>
            <td width="80%" valign="top">
                 <p><a href="https://arxiv.org/abs/2204.06213">
                 <papertitle>Defensive Patches for Robust Recognition in the Physical World</papertitle></a>
                 <br>Jiakai Wang, Zixin Yin, Pengfei Hu, Renshuai Tao, Haotong Qin, Xianglong Liu, Dacheng Tao, <strong>Aishan Liu</strong>.<br>
                 <em>IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</em>, 2022
				 <br>
                 <a href="https://arxiv.org/abs/2204.06213">pdf</a>  /
				<a href="https://github.com/nlsde-safety-team/DefensivePatch"><font color="red">Project page</font></a>
                 <iframe src="https://ghbtns.com/github-btn.html?user=nlsde-safety-team&repo=DefensivePatch&type=star&count=true&size=small" frameborder="0" scrolling="0" width="120px" height="20px"></iframe>
				
               
                 <p align="justify" style="font-size:13px"> We generate defensive patches to help building robust recognition systems in practice against noises by simply sticking them on the target object.</p>
                <p></p>
            </td>
        </tr>
		
				   <td width="20%"><img src="./imgs/CVPR2022-2.png" alt="CVPR 2022" width="180" height = "180" style="border-style: none"></td>
            <td width="80%" valign="top">
                 <p><a href="#">
                 <papertitle>Exploring Endogenous Shift for Cross-domain Detection: A Large-scale Benchmark and Perturbation Suppression Network</papertitle></a>
                 <br>Renshuai Tao, Hainan Li, Tianbo Wang, Yanlu Wei, Yifu Ding, Bowei Jin, Hongping Zhi, Xianglong Liu, <strong>Aishan Liu</strong>.<br>
                 <em>IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</em>, 2022
				 <br>
                 <a href="https://arxiv.org/pdf/2108.10515.pdf">pdf</a> 
               
                 <p align="justify" style="font-size:13px"> This paper proposes Endogenous Domain Shift that measures the noises caused by different X-ray machine types with different hardware parameters, which can severely harm the cross-domain detection robustness.</p>
                <p></p>
            </td>
        </tr>
		
		   <td width="20%"><img src="./imgs/ICLR2022.png" alt="ICLR2021" width="180" height = "110" style="border-style: none"></td>
            <td width="80%" valign="top">
                 <p><a href="https://openreview.net/pdf?id=5xEgrl_5FAJ">
                 <papertitle>BIBERT: Accurate Fully Binarized BERT</papertitle></a>
                 <br>Haotong Qin, Yifu Ding, Mingyuan Zhang, Qinghua Yan, <strong>Aishan Liu</strong>, Qingqing Dang, Ziwei Liu, Xianglong Liu<br>
                 <em>International Conference on Learning Representations (ICLR)</em>, 2022
                 <br>
                 <a href="https://openreview.net/pdf?id=5xEgrl_5FAJ">pdf</a> 
				 
                <!--/<font color="red"> News:</font>
                <a href="https://mp.weixin.qq.com/s/cIcJvmkbvQk-W_qJADkSqw"><font color="red">(机器之心)</font></a>-->
                /
				<a href="https://github.com/htqin/BiBERT"><font color="red">Project page</font></a>
                 <iframe src="https://ghbtns.com/github-btn.html?user=htqin&repo=BiBERT&type=star&count=true&size=small" frameborder="0" scrolling="0" width="120px" height="20px"></iframe>
				
                 <p align="justify" style="font-size:13px">In this paper, we propose BiBERT, an accurate fully binarized BERT to eliminate the performance bottlenecks for large pre-trained BERT binarization.</p>
                <p></p>
            </td>
        </tr>
		
		
		   <td width="20%"><img src="./imgs/acmmm21.png" alt="ACM MM2021" width="180" height = "110" style="border-style: none"></td>
            <td width="80%" valign="top">
                 <p><a href="https://arxiv.org/pdf/2108.10515.pdf">
                 <papertitle>ARShoe: Real-Time Augmented Reality Shoe Try-on System on Smartphones</papertitle></a>
                 <br>Shan An, Guangfu Che, Jinghao Guo, Haogang Zhu, Junjie Ye, Fangru Zhou, Zhaoqi Zhu, Dong Wei, <strong>Aishan Liu</strong>, Wei Zhang.<br>
                 <em>ACM Multimedia (ACM MM)</em>, 2021
				 <br>
                 <a href="https://arxiv.org/pdf/2108.10515.pdf">pdf</a> 
               
                 <p align="justify" style="font-size:13px"> We propose a real-time augmented reality virtual shoe try-on system for smartphones, namely ARShoe. <font color="red">The system has been used in <a href="https://app.jd.com/">JD App</a>.</p></font>
                <p></p>
            </td>
        </tr>

   <td width="20%"><img src="./imgs/CVPR2021.png" alt="CVPR2021" width="180" height = "110" style="border-style: none"></td>
            <td width="80%" valign="top">
                 <p><a href="https://arxiv.org/pdf/2103.01050.pdf">
                 <papertitle>Dual Attention Suppression Attack: Generate Adversarial Camouflage in Physical World</papertitle></a>
                 <br>Jiakai Wang, <strong>Aishan Liu</strong>, Zixin Yin, Shunchang Liu, Shiyu Tang, Xianglong Liu.<br>
                 <em>IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</em>, 2021
				 <font color="red"><strong>(Oral)</strong></font>
                 <br>
                 <a href="https://arxiv.org/pdf/2103.01050.pdf">pdf</a> /
                <font color="red"> News:</font>
                <a href="https://mp.weixin.qq.com/s/cIcJvmkbvQk-W_qJADkSqw"><font color="red">(机器之心)</font></a>
                /<a href="https://github.com/liuaishan/SpatiotemporalAttack"><font color="red">Project page</font></a>
                 <iframe src="https://ghbtns.com/github-btn.html?user=nlsde-safety-team&repo=DualAttentionAttack&type=star&count=true&size=small" frameborder="0" scrolling="0" width="120px" height="20px"></iframe>
				
                 <p align="justify" style="font-size:13px">We propose the Dual Attention Suppression (DAS) attack to generate visually-natural physical adversarial camouflages with strong transferability by suppressing both model and human attention. </p>
                <p></p>
            </td>
        </tr>
		

   <td width="20%"><img src="./imgs/ECCV_1.png" alt="eccv2020" width="180" height = "110" style="border-style: none"></td>
            <td width="80%" valign="top">
                 <p><a href="https://arxiv.org/pdf/2005.09161.pdf">
                 <papertitle>Spatiotemporal Attacks for Embodied Agents</papertitle></a>
                 <br><strong>Aishan Liu</strong>, Tairan Huang, Xianglong Liu, Yitao Xu, Yuqing Ma, Xinyun Chen, Stephen Maybank, Dacheng Tao.<br>
                 <em>European Conference on Computer Vision (ECCV)</em>, 2020
                 <br>
                 <a href="https://arxiv.org/pdf/2005.09161.pdf">pdf</a> /
                <font color="red"> News:</font>
                <a href="https://www.qbitai.com/2020/07/16562.html"><font color="red">(量子位)</font></a>
                /<a href="https://github.com/liuaishan/SpatiotemporalAttack"><font color="red">Project page</font></a>
                 <iframe src="https://ghbtns.com/github-btn.html?user=liuaishan&repo=SpatiotemporalAttack&type=star&count=true&size=small" frameborder="0" scrolling="0" width="120px" height="20px"></iframe>
				
                 <p align="justify" style="font-size:13px">We take the first step to study adversarial attacks for embodied agents. </p>
                <p></p>
            </td>
        </tr>
		
   <td width="20%"><img src="./imgs/ECCV_2.png" alt="eccv2020" width="180" height = "110" style="border-style: none"></td>
            <td width="80%" valign="top">
                 <p><a href="https://arxiv.org/pdf/2005.09257.pdf">
                 <papertitle>Bias-based Universal Adversarial Patch Attack for Automatic Check-out</papertitle></a>
                 <br><strong>Aishan Liu</strong>, Jiakai Wang, Xianglong Liu, Bowen Cao, Chongzhi Zhang, Hang Yu.<br>
                 <em>European Conference on Computer Vision (ECCV)</em>, 2020
                 <br>
                 <a href="https://arxiv.org/pdf/2005.09257.pdf">pdf</a> /
                <font color="red"> News:</font>
                <a href="https://mp.weixin.qq.com/s?__biz=MzI3MTA0MTk1MA==&mid=2652073635&idx=5&sn=b1acd091996cacb9e74053c4208b793c&chksm=f1201a52c6579344ae75ccb2ee3042ed3eddbb6bd988000c7b1ba8c274f1aceaec7ea1300d1d&mpshare=1&scene=1&srcid=07082kvhcWURQF4VRcIx8uU9&sharer_sharetime=1596855924325&sharer_shareid=da9c9379a79901c18dc93793609d62fa&key=4defdd0e8978fadbc4f7d3467b572eb060d5482035de4befee54b935c6aabbcaafa3ed60343840f82abb27fbcc57798b93e6f215c44f11a37e87141722c58b1167ffeba220d7150c5c8ee9333d06f513&ascene=1&uin=MTQzMTA0NDAw&devicetype=Windows+10+x64&version=62090529&lang=zh_CN&exportkey=AfGxCG3P9erzoZeJcwLMjbg%3D&pass_ticket=qME0ljezjearOlDwgFgo%2F6ZH0VZ%2B7CLScg%2FNCc5rqMk%3D"><font color="red">(新智元)</font></a>
                /<a href="https://github.com/liuaishan/ModelBiasedAttack"><font color="red">Project page</font></a>
                 <iframe src="https://ghbtns.com/github-btn.html?user=liuaishan&repo=ModelBiasedAttack&type=star&count=true&size=small" frameborder="0" scrolling="0" width="120px" height="20px"></iframe>
				
                 <p align="justify" style="font-size:13px">We propose a bias-based framework to generate class-agnostic universal adversarial patches with strong generalization ability, which exploits both the perceptual and semantic bias of models.  </p>
                <p></p>
            </td>
        </tr>


        <td width="20%"><img src="./imgs/IJCAI2020_1.png" alt="ijcai2019" width="180" height = "110" style="border-style: none"></td>
            <td width="80%" valign="top">
                 <p><a href="https://www.ijcai.org/Proceedings/2020/0113.pdf">
                 <papertitle>Few-shot Visual Learning with Contextual Memory and Fine-grained Calibration</papertitle></a>
                 <br>Yuqing Ma, Shihao Bai, Wei Liu, Qingyu Zhang, <strong> Aishan Liu </strong>, Weimin Chen, Xianglong Liu<br>
                 <em>International Joint Conference on Artificial Intelligence (IJCAI)</em>, 2020
                 <br>
                 <a href="https://www.ijcai.org/Proceedings/2020/0113.pdf">pdf</a>
                 <p align="justify" style="font-size:13px">To improve the generalization ability of few-shot learning, we propose an inverted pyramid network that intimates the human’s coarse-to-fine cognition paradigm.</p>
                <p></p>
            </td>
        </tr>
		
		

        <td width="20%"><img src="./imgs/IJCAI2020_2.png" alt="ijcai2020" width="180" height="110" style="border-style: none"></td>
            <td width="80%" valign="top">
                 <p><a href="https://www.ijcai.org/Proceedings/2020/0112.pdf">
                 <papertitle>Transductive Relation-Propagation Network for Few-shot Learning</papertitle></a>
                 <br>Yuqing Ma, Shihao Bai, Shan An, Wei Liu, <strong>Aishan Liu</strong>, Xiantong Zhen, Xianglong Liu.<br>
                 <em>International Joint Conference on Artificial Intelligence (IJCAI)</em>, 2020
                 <br>
                 <a href="https://www.ijcai.org/Proceedings/2020/0112.pdf">pdf</a> /
				 <a href="https://github.com/vickyFox/TRPN"><font color="red">Project page</font></a>
                 <iframe src="https://ghbtns.com/github-btn.html?user=vickyFox&repo=TRPN&type=star&count=true&size=small" frameborder="0" scrolling="0" width="120px" height="20px"></iframe>
				
                 <p align="justify" style="font-size:13px">For few-shot learning task, we propose a transductive relation-propagation graph neural network to explicitly model and propagate such relations across support-query pairs. </p>
                <p></p>
            </td>
        </tr>
		
        <td width="20%"><img src="./imgs/ijcai19.png" alt="ijcai2019" width="180" height = "110" style="border-style: none"></td>
            <td width="80%" valign="top">
                 <p><a href="https://www.ijcai.org/Proceedings/2019/433">
                 <papertitle>Coarse-to-Fine Image Inpainting via Region-wise Convolutions and Non-Local Correlation</papertitle></a>
                 <br>Yuqing Ma, Xianglong Liu, Shihao Bai, Lei Wang, Dailan He, <strong> Aishan Liu </strong><br>
                 <em>International Joint Conference on Artificial Intelligence (IJCAI)</em>, 2019
                 <br>
                 <a href="https://www.ijcai.org/Proceedings/2019/433">pdf</a>
                 <p align="justify" style="font-size:13px"> To address the image inpainting problem, we propose a coarse-to-fine framework to restore semantically reasonable and visually realistic images, which consists region-wise convolutions to locally deal with the different types of regions and non-local operations to globally model the correlation among different regions.</p>
                <p></p>
            </td>
        </tr>

        <td width="20%"><img src="./imgs/aaai19.png" alt="aaai2019" width="180" height = "110" style="border-style: none"></td>
            <td width="80%" valign="top">
                 <p><a href="https://ojs.aaai.org//index.php/AAAI/article/view/3893">
                 <papertitle>Perceptual Sensitive GAN for Generating Adversarial Patches</papertitle></a>
                 <br><strong>Aishan Liu</strong>, Xianglong Liu, Jiaxin Fan, Yuqing Ma, Anlan Zhang, Huiyuan Xie and Dacheng Tao.<br>
                 <em>AAAI Conference on Artificial Intelligence (AAAI)</em>, 2019
				 <font color="red"><strong>(Spotlight)</strong></font>
                 <br>
                 <a href="https://ojs.aaai.org//index.php/AAAI/article/view/3893">pdf</a> /
                <font color="red"> News:</font>
                <a href="https://mp.weixin.qq.com/s?__biz=MzI3MTA0MTk1MA==&mid=2652044274&idx=3&sn=5e2570c25133c03e30930fdc9b04f2f8&chksm=f1218f03c65606157a07db05cad07264a38171038a8de33b667f21af001c76d3baaa501a7506&mpshare=1&scene=1&srcid=08085db4ycxZdHGWEPBNfGv7&sharer_sharetime=1596855953802&sharer_shareid=da9c9379a79901c18dc93793609d62fa&key=4bdaf1520bf406e77cac6eeb1e04025fad0a6dfcc38554ec2ae8223439dee1b518b3e5e70aa6d4335a271be601450da62f8d4466fe85fc3717b9650521117d32b52c3d3727bc25459b0c6e722caad691&ascene=1&uin=MTQzMTA0NDAw&devicetype=Windows+10+x64&version=62090529&lang=zh_CN&exportkey=ARP19W6ltvF%2B%2B%2BBJE5uc728%3D&pass_ticket=qME0ljezjearOlDwgFgo%2F6ZH0VZ%2B7CLScg%2FNCc5rqMk%3D"><font color="red">(新智元,</font></a>
                <a href="https://cloud.tencent.com/developer/article/1425611"><font color="red">腾讯,</font></a>
                <a href="https://www.163.com/dy/article/EEGALRRB0511ABV6.html"><font color="red">网易)</font></a>
                 <p align="justify" style="font-size:13px">We propose a PS-GAN framework to generate adversarial patches to attack auto-driving systems in the physical world. </p>
                <p></p>
            </td>
        </tr>
		</tbody>
		</table>
		
		<h3>&nbsp;&nbsp;&nbsp;&nbsp;Journal Papers</h3>
		
		
		  <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
		<tbody>
		
		
		<tr>
		<td width="20%"><img src="./imgs/PR2023.png" alt="PR2023" width="180" height = "110" style="border-style: none"></td>
            <td width="80%" valign="top">
                 <p><a href="https://arxiv.org/pdf/2101.09617.pdf">
                 <papertitle>A Comprehensive Evaluation Framework for Deep Model Robustness</papertitle></a>
                 <br>Jun Guo, Wei Bao, Jiakai Wang, Yuqing Ma, Xinghai Gao, Gang Xiao, <strong>Aishan Liu<sup>&spades;</sup></strong>, Jian Dong, Xianglong Liu, Wenjun Wu.<br>(&spades; indicates corresponding author)<br><br>
                 <em>Pattern Recognition (PR)</em>, 2023
				 <font color="red"><strong>(IF=8.35)</strong></font>
                 <br>
                 <a href="https://arxiv.org/pdf/2101.09617.pdf">pdf</a>
				 / <a href="#"></a>

                 <p align="justify" style="font-size:13px">This paper establishes a model robustness evaluation framework containing 23 comprehensive and rigorous metrics, which consider two key perspectives of adversarial learning (i.e., data and model).</p>
                <p></p>
            </td>
        </tr>
		
		<tr>
		
		<td width="20%"><img src="./imgs/cjc2023.png" alt="计算机学报" width="180" height = "110" style="border-style: none"></td>
            <td width="80%" valign="top">
                 <p><a href="https://ieeexplore.ieee.org/document/9462815">
                 <papertitle>面向深度强化学习的对抗攻防综述</papertitle></a>
                 <br><strong>Aishan Liu</strong>, Jun Guo, Simin Li, Yisong Xiao, Xianglong Liu, Dacheng Tao <br>
                 <em>计算机学报 (Chinese Journal of Computers)</em>, 2023
				 <font color="red"><strong>(CCF-A)</strong></font>
                 <br>
                 <a href="#">pdf</a>
				
                 <p align="justify" style="font-size:13px"> To better understand and further promote the development of deep reinforcement learning, this paper provides a comprehensive and systematic survey on the research development of adversarial attacks and defenses in the deep reinforcement learning area.</p>
                <p></p>
            </td>
        </tr>
		
		<td width="20%"><img src="./imgs/tmm2023.png" alt="TMM2023" width="180" height = "110" style="border-style: none"></td>
            <td width="80%" valign="top">
                 <p><a href="https://ieeexplore.ieee.org/document/9462815">
                 <papertitle>Temporal Speciation Network for Few-Shot Object Detection</papertitle></a>
                 <br>Xiaowei Zhao, Xianglong Liu, Yuqing Ma, Shihao Bai, Yifan Shen, Zeyu Hao, <strong>Aishan Liu</strong><br>
                 <em>IEEE Transactions on Multimedia (TMM)</em>, 2023
				 <font color="red"><strong>(IF=8.18)</strong></font>
                 <br>
                 <a href="https://ieeexplore.ieee.org/document/9462815">pdf</a>
				 / <a href="#"></a>

                 <p align="justify" style="font-size:13px">This paper presents a simple yet effective few-shot object detection framework referred to as Temporal Speciation Network (TeSNet) with an evolving training, which improves the diversity and ratonality of positive proposal generation.</p>
                <p></p>
            </td>
        </tr>
		
		<td width="20%"><img src="./imgs/aco-tip.png" alt="TIP2021" width="180" height = "110" style="border-style: none"></td>
            <td width="80%" valign="top">
                 <p><a href="https://ieeexplore.ieee.org/document/9462815">
                 <papertitle>Universal Adversarial Patch Attack for Automatic Checkout using Perceptual and Attentional Bias</papertitle></a>
                 <br>Jiakai Wang*, <strong>Aishan Liu*</strong>,  Xiao Bai, Xianglong Liu <br>(* indicates equal contributions)<br>
                 <em>IEEE Transactions on Image Processing (TIP)</em>, 2021
				 <font color="red"><strong>(IF=10.86)</strong></font>
                 <br>
                 <a href="https://ieeexplore.ieee.org/document/9462815">pdf</a>
				 / <a href="https://github.com/nlsde-safety-team/PerceptualAttentionalBiasedAttack"><font color="red">Project page</font></a>
                 <iframe src="https://ghbtns.com/github-btn.html?user=nlsde-safety-team&repo=PerceptualAttentionalBiasedAttack&type=star&count=true&size=small" frameborder="0" scrolling="0" width="120px" height="20px"></iframe>

                 <p align="justify" style="font-size:13px"> We propose a bias-based framework to generate universal adversarial patches with strong generalization ability, which exploits the perceptual bias and attentional bias to improve the attacking ability.</p>
                <p></p>
            </td>
        </tr>

		<td width="20%"><img src="./imgs/tip-pda.png" alt="TIP2021" width="180" height = "110" style="border-style: none"></td>
            <td width="80%" valign="top">
                 <p><a href="https://ieeexplore.ieee.org/document/9462815">
                 <papertitle>Progressive Diversified Augmentation for General Robustness of DNNs: A Unified Approach</papertitle></a>
                 <br>Hang Yu, <strong>Aishan Liu<sup>&spades;</sup></strong>,  Gengchao Li, Jichen Yang, Chongzhi Zhang <br>(&spades; indicates corresponding author)<br>
                 <em>IEEE Transactions on Image Processing (TIP)</em>, 2021
				 <font color="red"><strong>(IF=10.86)</strong></font>
                 <br>
                 <a href="https://ieeexplore.ieee.org/document/9462815">pdf</a> / <a href="https://github.com/DIG-Beihang/AISafety"><font color="red">Project page</font></a>
				<iframe src="https://ghbtns.com/github-btn.html?user=DIG-Beihang&repo=AISafety&type=star&count=true&size=small" frameborder="0" scrolling="0" width="120px" height="20px"></iframe>
                 <p align="justify" style="font-size:13px"> We propose a simple yet effective method, named Progressive Diversified Augmentation (PDA), which improves the robustness of DNNs towards both adversarial attacks and common corruptions by progressively injecting diverse adversarial noises during training.</p>
                <p></p>
            </td>
        </tr>
		
		<td width="20%"><img src="./imgs/neucom.png" alt="NeuCom2021" width="180" height = "110" style="border-style: none"></td>
            <td width="80%" valign="top">
                 <p><a href="#">
                 <papertitle>Revisiting Audio Visual Scene-Aware Dialog</papertitle></a>
                 <br><strong>Aishan Liu</strong>, Huiyuan Xie, Xianglong Liu, Zixin Yin, Shunchang Liu<br>
                 <em>NeuroComputing</em>, 2021
				 <font color="red"><strong>(IF=5.72)</strong></font>
                 <br>
                 <a href="https://www.sciencedirect.com/science/article/abs/pii/S0925231222001783">pdf</a>
				 <!--<a href="https://github.com/DIG-Beihang/AISafety"><font color="red">Project page</font></a>
                 <iframe src="https://ghbtns.com/github-btn.html?user=DIG-Beihang&repo=AISafety&type=star&count=true&size=small" frameborder="0" scrolling="0" width="120px" height="20px"></iframe>
				-->
                 <p align="justify" style="font-size:13px"> This paper empirically revisits the AVSD task and argues that this task exhibits a variety of biases in terms of models, dataset, and evaluation metrics.</p>
                <p></p>
            </td>
        </tr>
		
				<td width="20%"><img src="./imgs/tnnls21.png" alt="TNNLS2021" width="180" height = "110" style="border-style: none"></td>
            <td width="80%" valign="top">
                 <p><a href="https://ieeexplore.ieee.org/document/9509344">
                 <papertitle>On the Guaranteed Almost Equivalence Between Imitation Learning From Observation and Demonstration</papertitle></a>
                 <br>Zhihao Cheng, Liu Liu, <strong>Aishan Liu</strong>, Hao Sun, Meng Fang, Dacheng Tao<br>
                 <em>IEEE Transactions on Neural Networks and Learning Systems (TNNLS)</em>, 2021
				 <font color="red"><strong>(IF=10.45)</strong></font>
                 <br>
                 <a href="https://ieeexplore.ieee.org/document/9509344">pdf</a>
                 <p align="justify" style="font-size:13px"> In contrast to previous studies, this paper first proves that LfO is almost equivalent to LfD in the deterministic robot environment, and more generally even in the robot environment with bounded randomness.</p>
                <p></p>
            </td>
        </tr>
		
		<td width="20%"><img src="./imgs/anp.png" alt="TIP2021" width="180" height = "110" style="border-style: none"></td>
            <td width="80%" valign="top">
                 <p><a href="https://ieeexplore.ieee.org/document/9462815">
                 <papertitle>Training Robust Deep Neural Networks via Adversarial Noise Propagation</papertitle></a>
                 <br><strong>Aishan Liu</strong>, Xianglong Liu, Hang Yu, Chongzhi Zhang, Qiang Liu, Dacheng Tao<br>
                 <em>IEEE Transactions on Image Processing (TIP)</em>, 2021
				 <font color="red"><strong>(IF=10.86)</strong></font>
                 <br>
                 <a href="https://ieeexplore.ieee.org/document/9462815">pdf</a>
				 <a href="https://github.com/DIG-Beihang/AISafety"><font color="red">Project page</font></a>
                 <iframe src="https://ghbtns.com/github-btn.html?user=DIG-Beihang&repo=AISafety&type=star&count=true&size=small" frameborder="0" scrolling="0" width="120px" height="20px"></iframe>
                 <p align="justify" style="font-size:13px"> We propose a simple yet powerful training algorithm to improve model robustness, named Adversarial Noise Propagation (ANP), which injects noise into the hidden layers in a layer-wise manner. ANP can be implemented efficiently by exploiting the nature of the backward-forward training style.</p>
                <p></p>
            </td>
        </tr>
		
		<td width="20%"><img src="./imgs/SNS.png" alt="TIP2021" width="180" height = "110" style="border-style: none"></td>
            <td width="80%" valign="top">
                 <p><a href="https://arxiv.org/pdf/1909.06978.pdf">
                 <papertitle>Interpreting and Improving Adversarial Robustness of Deep Neural Networks with Neuron Sensitivity</papertitle></a>
                 <br>Chongzhi Zhang*, <strong>Aishan Liu*</strong>, Xianglong Liu, Yitao Xu, Hang Yu, Yuqing Ma, Tianlin Li (* indicates equal contributions)<br>
                 <em>IEEE Transactions on Image Processing (TIP)</em>, 2021
				 <font color="red"><strong>(IF=10.86)</strong></font>
                 <br>
                 <a href="https://arxiv.org/pdf/1909.06978.pdf">pdf</a> /
				 <a href="https://github.com/DIG-Beihang/AISafety"><font color="red">Project page</font></a>
                 <iframe src="https://ghbtns.com/github-btn.html?user=DIG-Beihang&repo=AISafety&type=star&count=true&size=small" frameborder="0" scrolling="0" width="120px" height="20px"></iframe>
				
                 <p align="justify" style="font-size:13px">We are the first to explain adversarial robustness for deep models from the perspective of neuron sensitivity, which is measured by neuron behavior variation intensity against benign and adversarial examples.</p>
                <p></p>
            </td>
        </tr>
		
		<td width="20%"><img src="./imgs/INS_1.png" alt="TIP2021" width="180" height = "110" style="border-style: none"></td>
            <td width="80%" valign="top">
                 <p><a href="https://doi.org/10.1016/j.ins.2020.08.043">
                 <papertitle>Understanding Adversarial Robustness via Critical Attacking Route</papertitle></a>
                 <br>Tianlin Li*, <strong>Aishan Liu*</strong>, Xianglong Liu, Yitao Xu, Chongzhi Zhang, Xiaofei Xie (* indicates equal contributions)<br>
                 <em>Information Sciences</em>, 2020
				 <font color="red"><strong>(IF=5.91)</strong></font>
                 <br>
                 <a href="https://doi.org/10.1016/j.ins.2020.08.043">pdf</a> /
				 <a href="https://github.com/DIG-Beihang/AISafety"><font color="red">Project page</font></a>
                 <iframe src="https://ghbtns.com/github-btn.html?user=DIG-Beihang&repo=AISafety&type=star&count=true&size=small" frameborder="0" scrolling="0" width="120px" height="20px"></iframe>
				
                 <p align="justify" style="font-size:13px">We try to explain adversarial robustness for deep models from a new perspective of critical attacking route, which is computed by a gradient-based influence propagation strategy.</p>
                <p></p>
            </td>
        </tr>
		
		<td width="20%"><img src="./imgs/AI-View.png" alt="AIView" width="180" height = "110" style="border-style: none"></td>
            <td width="80%" valign="top">
                 <p><a href="http://www.cesi.ac.cn/202007/6566.html">
                 <papertitle>人工智能安全与评测</papertitle></a>
                 <br> <strong>刘艾杉</strong>, 王嘉凯, 刘祥龙<br>
                 <em>人工智能(AI-View)</em>, 2020
				 
                 <br>
                 <a href="http://www.cesi.ac.cn/202007/6566.html">pdf</a> 
                 
                <p></p>
            </td>
        </tr>
	
			<td width="20%"><img src="./imgs/Eval_1.png" alt="AIView" width="180" height = "110" style="border-style: none"></td>
            <td width="80%" valign="top">
                 <p><a href="http://www.cesi.ac.cn/202007/6566.html">
                 <papertitle>人工智能机器学习模型及系统的质量要素和测试方法</papertitle></a>
                 <br> 王嘉凯, <strong>刘艾杉</strong>, 刘祥龙<br>
                 <em>信息技术与标准化</em>, 2020
				 
                 <br>
                 <a href="http://www.cesi.ac.cn/202007/6566.html">pdf</a> 
                 
                <p></p>
            </td>
        </tr>
	



        </tbody>
    </table>


    <!--Thesis  -->
    <table width="100%" align="center" border="0" cellspacing="0" cellpadding="10">
        <tbody><tr>
          <td><heading>Highlight Project</heading>
          </tr></tbody>
    </table>
    <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
		<tbody><tr>
        <td width="20%"><img src="./imgs/logo设计-02.png" alt="PontTuset" width="180" height="160" style="border-style: none"></td>
            <td width="80%" valign="top">
                 <p><a href="https://arxiv.org/pdf/2101.09617.pdf">
                 <papertitle>重明 (AISafety)</papertitle></a>
                 <br>
                  <br>
                 <a href="https://arxiv.org/pdf/2101.09617.pdf">pdf</a> /
				  <a href="http://www.techweb.com.cn/2020-12-02/2814466.shtml"><font color="red"> (News: TechWeb)</font></a> /
				 <a href="https://github.com/DIG-Beihang/AISafety"><font color="red">Project page</font></a>
                 <iframe src="https://ghbtns.com/github-btn.html?user=DIG-Beihang&repo=AISafety&type=star&count=true&size=small" frameborder="0" scrolling="0" width="120px" height="20px"></iframe>
				
                
                 <p align="justify" style="font-size:13px">重明 is an open-source platform to evaluate model robustness and safety towards noises (e.g., adversarial examples, corruptions, etc.). 
				 The name is taken from the Chinese myth <a href="https://baike.baidu.com/item/%E9%87%8D%E6%98%8E%E9%B8%9F/5482222?fr=aladdin">重明鸟</a>, which has strong power, could fight against beasts and avoid disasters. 
				 We hope our platform could improve the robustness of deep learning systems and help them to avoid safety-related problems. 
				 重明 has been awarded the <a href="http://www.techweb.com.cn/2020-12-02/2814466.shtml">首届OpenI启智社区优秀开源项目</a> (First OpenI Excellent Open Source Project).
                 </p>
                <p></p>
            </td>
        </tr>

        </tbody>
    </table>
	
    <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
		<tbody><tr>
        <td width="20%"><img src="./imgs/robustart.png" alt="PontTuset" width="180" height="160" style="border-style: none"></td>
            <td width="80%" valign="top">
                 <p><a href="https://arxiv.org/pdf/2101.09617.pdf">
                 <papertitle>RobustART</papertitle></a>
                 <br>
                  <br>
                 <a href="https://arxiv.org/pdf/2109.05211.pdf">pdf</a> /
				  <a href="https://baijiahao.baidu.com/s?id=1711221498985379616&wfr=spider&for=pc"><font color="red"> (News: 机器之心)</font></a> /
				 <a href="http://robust.art/"><font color="red">Project page</font></a>
                 <iframe src="https://ghbtns.com/github-btn.html?user=DIG-Beihang&repo=RobustART&type=star&count=true&size=small" frameborder="0" scrolling="0" width="120px" height="20px"></iframe>
				
                
                 <p align="justify" style="font-size:13px">RobustART is the first comprehensive Robustness investigation benchmark on large-scale dataset ImageNet regarding ARchitectural design (49 human-designed off-the-shelf architectures and 1200+ neural architecture searched networks) and Training techniques (10+ general ones e.g., extra training data, etc) towards diverse noises (adversarial, natural, and system noises). 
				 Our benchmark (including open-source toolkit, pre-trained model zoo, datasets, and analyses): 
				 (1) presents an open-source platform for conducting comprehensive evaluation on diverse robustness types; (2) provides a variety of pre-trained models with different training techniques to facilitate robustness evaluation; (3) proposes a new view to better understand the mechanism towards designing robust DNN architectures, backed up by the analysis. 
				 We will continuously contribute to building this ecosystem for the community.
                 </p>
                <p></p>
            </td>
        </tr>

        </tbody>
    </table>

    <!--SECTION 6 -->
    <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
         <tbody><tr>
            <td><heading>Talks & Academic Services</heading>
			<p style="font-size:13px"> <strong>[2021.08]</strong> Co-organizer of the Workshop on <a href="https://practical-dl.github.io/">1st International Workshop on Practical Deep Learning in the Wild</a> at AAAI 2022. </p>
             <p style="font-size:13px"> <strong>[2021.08]</strong> Co-organizer of the Forum on Safety and Privacy on Pattern Recognition at <a href="http://www.prcv.cn/">PRCV 2021</a>. </p>
             <p style="font-size:13px"> <strong>[2021.08]</strong> Co-organizer of the Forum on Safety and Privacy for Multimedia Systems at <a href="https://conf.ccf.org.cn/web/html7/TYMB.html?channelId=8a9e362c7b9bc357017ba11235630029&superChannel=8a9e362c7b9bc357017ba0fae29f0017&globalId=m8341723535535022081618923787260">ChinaMM 2021</a>. </p>        
			 <p style="font-size:13px"> <strong>[2021.03]</strong> Co-organizer of the Workshop on <a href="https://advm-workshop-2021.github.io/">1st International Workshop on Adversarial Learning for Multimedia</a> at ACM MM 2021. </p>
             <p style="font-size:13px"> <strong>[2020.12]</strong> Invited talk about Adversarial Machine Learning at <a href="https://zhidx.com/p/246975.html">智东西公开课(Zhidx)</a></p>
             <p style="font-size:13px"> <strong>[2020.11]</strong> Invited talk about Adversarial Attacks for Embodiment at <a href="http://www.csai.tsinghua.edu.cn/">CSAI, Tsinghua University</a>, hosted by <a href="http://www.cs.tsinghua.edu.cn/publish/cs/4616/2013/20131122152618871262231/20131122152618871262231_.html">Prof. Huaping Liu</a>.</p>
             <p style="font-size:13px"> <strong>[2020.08]</strong> Invited talk about AI Safety in Automatic Check-out Scenario at <a href="https://baijiahao.baidu.com/s?id=1675149234904040117&wfr=spider&for=pc">智东西公开课(Zhidx)</a></p>
             <p style="font-size:13px"> <strong>[2020.07]</strong> Invited talk about Adversarial Machine Learning in Physical World at JD.</p>
            </td>
            </tr></tbody>
    </table>


    <!--SECTION 7 -->
    <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
         <tbody><tr>
            <td><heading>Main Awards</heading>

			 <p style="font-size:13px"> <strong>[2020.12]</strong> First OpenI Excellent Open Source Project (Nationwide 7)</p>
             <p style="font-size:13px"> <strong>[2019.05]</strong> Tencent Rhino-Bird Elite Training Program (Nationwide 56)</p>
			 <p style="font-size:13px"> <strong>[2016.01]</strong> Outstanding Graduate Award, Beihang University</p>
			 <p style="font-size:13px"> <strong>[2013.06]</strong> Outstanding Graduate Award, Beijing</p>
			 <p style="font-size:13px"> <strong>[2012.10]</strong> CCF National Outstanding Undergraduate, China Computer Federation (Nationwide 100)</p>
			 <p style="font-size:13px"> <strong>[2012.06]</strong> Google Excellence Scholarship, Google (Nationwide 100)</p>
            </td>
            </tr></tbody>
    </table>

 


    <!--SECTION 9 -->
    <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
    <tbody><tr>
    <td width="100%" align="middle">
    <p align="center" style="width: 25% ">
	<script type="text/javascript" id="clstr_globe" src="//clustrmaps.com/globe.js?d=FNDqwJKuuuc-Jj3S56eFusOQvcz3NgFHJSeFgCtQVeQ"></script>
    </p></td>
    </tr>
    </tbody>
    </table>


    <!--SECTION 10 -->
    <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
         <tbody><tr>
            <td><br>
               <!--<p align="right"><font size="3">Erd&ouml;s = ? </font><br> -->
		       <p align="right"><font size="2"> Last update: 2022.11</font></p>
            </td>
         </tr>
         </tbody>
     </table>


</td>
</tr>
</tbody>
</table>
</body>
</html>
